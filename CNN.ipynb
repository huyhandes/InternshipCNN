{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from skimage import io\n",
    "import random\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
    "#np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIDCFilePath = \"/storage/huybq/LIDC/\"\n",
    "\n",
    "SOURCE_DATA_HEATMAP64 = LIDCFilePath + \"lidc_image/heatmap/heatmap_64/\"\n",
    "\n",
    "SOURCE_DATA_HEATMAP32 = LIDCFilePath + \"lidc_image/heatmap/heatmap_32/\"\n",
    "\n",
    "SOURCE_DATA_GREY64 = LIDCFilePath + \"lidc_image/grey/grey_64/\"\n",
    "\n",
    "SOURCE_DATA_GREY32 = LIDCFilePath + \"lidc_image/grey/grey_32/\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# INPUT_SHAPE = [None, IMAGE_SIZE, IMAGE_SIZE,CHANNELS]\n",
    "\n",
    "OUTPUT_SHAPE = 3\n",
    "\n",
    "MODEL_URL = \"https://tfhub.dev/google/imagenet/inception_v3/classification/4\"\n",
    "\n",
    "metadata = pd.read_csv('/storage/huybq/LIDC/csvData/metadata.csv')\n",
    "metadata32 = metadata.drop(metadata.loc[metadata['avail32'] == False].index)\n",
    "metadata64 = metadata.drop(metadata.loc[metadata['avail64'] == False].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quart(fileNames,texture):\n",
    "    random.seed(datetime.now())\n",
    "    quartFileName, tmp1, quartTexture, tmp2 = train_test_split(fileNames, \n",
    "                                                               texture, test_size=0.75,\n",
    "                                                               random_state = 99)\n",
    "    return quartFileName,quartTexture\n",
    "def get_random_sample(class_data,index):\n",
    "    random.seed(datetime.now())\n",
    "    fileName_train = np.asarray([])\n",
    "    texture_train = np.asarray([])\n",
    "    fileName_valid = np.asarray([])\n",
    "    texture_valid = np.asarray([])\n",
    "    fileName_test = np.asarray([])\n",
    "    texture_test = np.asarray([])\n",
    "    sampleFileName_train, sampleFileName_valid, sampleTexture_train, sampleTexture_valid = train_test_split(class_data[:,0],\n",
    "                                                                              class_data[:,1],\n",
    "                                                                              test_size = 0.3,\n",
    "                                                                              random_state=99)\n",
    "    sampleFileName_valid, sampleFileName_test, sampleTexture_valid, sampleTexture_test = train_test_split(sampleFileName_valid,\n",
    "                                                                              sampleTexture_valid,\n",
    "                                                                              test_size = 0.333,\n",
    "                                                                              random_state=99)\n",
    "    #generate each image in trainset\n",
    "    for i in range(sampleFileName_train.shape[0]):\n",
    "        offsetFileName, offsetTexture = generator_with_offset(sampleFileName_train[i],sampleTexture_train[i])\n",
    "        fileName_train = np.append(fileName_train,offsetFileName)\n",
    "        texture_train = np.append(texture_train,offsetTexture)\n",
    "    #generate each image in validset\n",
    "    for i in range(sampleFileName_valid.shape[0]):\n",
    "        offsetFileName, offsetTexture = generator_with_offset(sampleFileName_valid[i],sampleTexture_valid[i])\n",
    "        fileName_valid = np.append(fileName_valid,offsetFileName)\n",
    "        texture_valid = np.append(texture_valid,offsetTexture)\n",
    "    #generate each image in validset\n",
    "    for i in range(sampleFileName_test.shape[0]):\n",
    "        offsetFileName, offsetTexture = generator_with_offset(sampleFileName_test[i],sampleTexture_test[i], test = True)\n",
    "        fileName_test = np.append(fileName_test,offsetFileName)\n",
    "        texture_test = np.append(texture_test,offsetTexture)\n",
    "    if index == 2:\n",
    "        fileName_train, texture_train = get_quart(fileName_train, texture_train)\n",
    "        fileName_valid, texture_valid = get_quart(fileName_valid, texture_valid)\n",
    "        fileName_test, texture_test = get_quart(fileName_test, texture_test)\n",
    "    return fileName_train, fileName_valid, fileName_test, texture_train, texture_valid, texture_test\n",
    "\n",
    "def get_boolen_texture(textures, classify = 'binary'):\n",
    "    if classify == 'binary':\n",
    "        unique_textures = np.asarray([1,2])\n",
    "        textures[textures == 2] = 1\n",
    "        textures[textures > 3] = 2\n",
    "    else:\n",
    "        unique_textures = np.asarray([1,2,3])\n",
    "        textures[textures == 2] = 1\n",
    "        textures[textures == 3] = 2\n",
    "        textures[textures > 3] = 3\n",
    "    return [texture == unique_textures for texture in textures]\n",
    "\n",
    "def generator_with_offset(fileName, texture, test = False):\n",
    "#     if test:\n",
    "    offsetFileNames = np.asarray([fileName+'.png'])\n",
    "    offsetTexture = np.repeat(texture,1)\n",
    "#         return offsetFileNames,offsetTexture\n",
    "#     if texture <= 3:\n",
    "#         offsetFileNames = np.asarray([fileName+'.png',fileName+'_flip.png',fileName+'_rotate.png',fileName+'_flip_rotate.png'])\n",
    "#         offsetTexture = np.repeat(texture,4)\n",
    "#     else: \n",
    "#         offsetFileNames = np.asarray([fileName+'.png'])\n",
    "#         offsetTexture = np.repeat(texture,1)\n",
    "    return offsetFileNames,offsetTexture\n",
    "\n",
    "def create_dataset(source_data):\n",
    "    all_data = source_data[['fileName','texture']].to_numpy()\n",
    "    all_data = all_data[np.argsort(all_data[:,1])]\n",
    "    value, count = np.unique(all_data[:,1], return_counts=True)\n",
    "    count = [count[0]+count[1],count[2],count[3]+count[4]]\n",
    "    count = [count[0],count[0]+count[1],count[0]+count[1]+count[2]]\n",
    "    \n",
    "    data_by_class = np.split(all_data,count[0:2])\n",
    "    \n",
    "    fileName_train_multi = np.asarray([])\n",
    "    texture_train_multi = np.asarray([])\n",
    "    fileName_valid_multi = np.asarray([])\n",
    "    texture_valid_multi = np.asarray([])\n",
    "    fileName_test_multi = np.asarray([])\n",
    "    texture_test_multi = np.asarray([])\n",
    "    \n",
    "    fileName_train_binary = np.asarray([])\n",
    "    texture_train_binary = np.asarray([])\n",
    "    fileName_valid_binary = np.asarray([])\n",
    "    texture_valid_binary = np.asarray([])\n",
    "    fileName_test_binary = np.asarray([])\n",
    "    texture_test_binary = np.asarray([])\n",
    "    \n",
    "    for index,data in enumerate(data_by_class):\n",
    "        testName_train, testName_valid, testName_test, testTexture_train, testTexture_valid, testTexture_test = get_random_sample(data,index)\n",
    "        #append train, valid, test data\n",
    "        if index != 1:\n",
    "            fileName_train_binary = np.append(fileName_train_binary,testName_train)\n",
    "            texture_train_binary = np.append(texture_train_binary,testTexture_train)\n",
    "            fileName_valid_binary = np.append(fileName_valid_binary,testName_valid)\n",
    "            texture_valid_binary = np.append(texture_valid_binary,testTexture_valid)\n",
    "            fileName_test_binary = np.append(fileName_test_binary,testName_test)\n",
    "            texture_test_binary = np.append(texture_test_binary,testTexture_test)\n",
    "            \n",
    "        fileName_train_multi = np.append(fileName_train_multi,testName_train)\n",
    "        texture_train_multi = np.append(texture_train_multi,testTexture_train)\n",
    "        fileName_valid_multi = np.append(fileName_valid_multi,testName_valid)\n",
    "        texture_valid_multi = np.append(texture_valid_multi,testTexture_valid)\n",
    "        fileName_test_multi = np.append(fileName_test_multi,testName_test)\n",
    "        texture_test_multi = np.append(texture_test_multi,testTexture_test)\n",
    "    return [fileName_train_multi, fileName_valid_multi, fileName_test_multi, get_boolen_texture(texture_train_multi,classify = 'multi'), get_boolen_texture(texture_valid_multi,classify = 'multi'), get_boolen_texture(texture_test_multi,classify = 'multi')],\\\n",
    "            [fileName_train_binary, fileName_valid_binary, fileName_test_binary, get_boolen_texture(texture_train_binary,classify = 'binary'), get_boolen_texture(texture_valid_binary,classify = 'binary'), get_boolen_texture(texture_test_binary,classify = 'binary')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(filePath):\n",
    "    image = tf.io.read_file(filePath)\n",
    "    image = tf.io.decode_png(image,channels = 0)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image,(224,224))\n",
    "    return image\n",
    "def get_image_label(filePath,texture):\n",
    "    image = process_image(filePath)\n",
    "    return image,texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_batches(X, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n",
    "    if test_data:\n",
    "        print(\"Creating test data batches...\")\n",
    "        data = tf.data.Dataset.from_tensor_slices((tf.constant(X),tf.constant(y)))\n",
    "        data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
    "        return data_batch\n",
    "    if valid_data:\n",
    "        print(\"Creating validation data batches...\")\n",
    "        data = tf.data.Dataset.from_tensor_slices((tf.constant(X),tf.constant(y)))\n",
    "        data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
    "        return data_batch\n",
    "    print(\"Creating training data batches...\")\n",
    "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X),tf.constant(y)))\n",
    "    data = data.shuffle(buffer_size=len(X))\n",
    "    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
    "    return data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(inputShape, outputShape, classify = 'binary', transfer = False):\n",
    "    #parameter\n",
    "    outputActivation = 'sigmoid' if classify == 'binary' else 'softmax'\n",
    "    LOSS = tf.keras.losses.BinaryCrossentropy() if classify == 'binary' else tf.keras.losses.CategoricalCrossentropy()\n",
    "    METRICS = [tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()] if classify == 'binary' else [tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()]\n",
    "    if transfer:\n",
    "         model = tf.keras.Sequential([\n",
    "             hub.KerasLayer(\"https://tfhub.dev/google/imagenet/inception_v3/classification/4\"),\n",
    "             tf.keras.layers.Dense(units=outputShape,activation=outputActivation)\n",
    "         ])\n",
    "    else:\n",
    "    #model\n",
    "        model = tf.keras.Sequential([\n",
    "            #layer 1\n",
    "            tf.keras.layers.Conv2D(32,5,strides = 1,padding = \"same\",input_shape = inputShape[1:] , data_format = 'channels_last',activation='relu'),\n",
    "            tf.keras.layers.Conv2D(32,5,strides = 1,padding = \"same\", data_format = 'channels_last',activation='relu'),\n",
    "            tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2, padding = \"valid\" ,data_format='channels_last'),\n",
    "            #layer 2\n",
    "            tf.keras.layers.Conv2D(64,3,strides = 1,padding = \"same\", data_format = 'channels_last',activation='relu'),\n",
    "            tf.keras.layers.Conv2D(64,3,strides = 1,padding = \"same\", data_format = 'channels_last',activation='relu'),\n",
    "            tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2, padding = \"valid\" ,data_format='channels_last'),\n",
    "            #layer 3\n",
    "            tf.keras.layers.Conv2D(128,1,strides = 1,padding = \"same\", data_format = 'channels_last',activation='relu'),\n",
    "            tf.keras.layers.Conv2D(128,1,strides = 1,padding = \"same\", data_format = 'channels_last',activation='relu'),\n",
    "            tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2, padding = \"same\" ,data_format='channels_last'),\n",
    "            #layer 4\n",
    "            tf.keras.layers.Conv2D(256,3,strides = 1,padding = \"same\", data_format = 'channels_last',activation='relu'),\n",
    "            tf.keras.layers.Conv2D(256,3,strides = 1,padding = \"same\", data_format = 'channels_last',activation='relu'),\n",
    "            tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2, padding = \"valid\" ,data_format='channels_last'),\n",
    "            #layer 5\n",
    "            tf.keras.layers.Conv2D(512,3,strides = 1,padding = \"same\", data_format = 'channels_last',activation='relu'),\n",
    "            tf.keras.layers.Conv2D(512,3,strides = 1,padding = \"same\", data_format = 'channels_last',activation='relu'),\n",
    "            tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2, padding = \"valid\" ,data_format='channels_last'),\n",
    "\n",
    "            tf.keras.layers.Flatten(),\n",
    "            #last layer\n",
    "            tf.keras.layers.Dense(units=128,activation='relu'),\n",
    "            tf.keras.layers.Dense(units=outputShape,activation=outputActivation)\n",
    "        ])\n",
    "    model.compile(\n",
    "      loss=LOSS,\n",
    "      optimizer=tf.keras.optimizers.Adam(1e-05),\n",
    "      metrics=METRICS\n",
    "    )\n",
    "    model.build(inputShape)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 32)        2432      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       8320      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 128)       16512     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 4,796,195\n",
      "Trainable params: 4,796,195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model([None,64,64,3],3,'multi')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_multi = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy',\n",
    "                                                  patience=10,\n",
    "                                                  restore_best_weights = True)\n",
    "learning_rate_reduce_multi = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy',\n",
    "                                                            patience=3,\n",
    "                                                            factor=0.02,\n",
    "                                                            min_lr=1e-08)\n",
    "early_stopping_binary = tf.keras.callbacks.EarlyStopping(monitor='val_binary_accuracy',\n",
    "                                                  patience=10,\n",
    "                                                  restore_best_weights = True)\n",
    "learning_rate_reduce_binary = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_binary_accuracy',\n",
    "                                                            patience=3,\n",
    "                                                            factor=0.02,\n",
    "                                                            min_lr=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "NUM_EPOCHS = 100\n",
    "[X_train_multi, X_valid_multi, X_test_multi, y_train_multi, y_valid_multi, y_test_multi],[X_train_binary, X_valid_binary, X_test_binary, y_train_binary, y_valid_binary, y_test_binary] = create_dataset(metadata32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850\n",
      "Creating training data batches...\n",
      "243\n",
      "Creating validation data batches...\n",
      "123\n",
      "Creating test data batches...\n",
      "667\n",
      "Creating training data batches...\n",
      "191\n",
      "Creating validation data batches...\n",
      "96\n",
      "Creating test data batches...\n"
     ]
    }
   ],
   "source": [
    "def add_source(fileNames):\n",
    "    print(len(fileNames))\n",
    "    sourceNames = np.asarray([])\n",
    "    for fileName in fileNames:\n",
    "        sourceNames = np.append(sourceNames, SOURCE_DATA_HEATMAP32 + fileName)\n",
    "    return sourceNames\n",
    "train_data_multi = create_data_batches(add_source(X_train_multi), y_train_multi)\n",
    "valid_data_multi = create_data_batches(add_source(X_valid_multi), y_valid_multi, valid_data = True)\n",
    "test_data_multi = create_data_batches(add_source(X_test_multi), y_test_multi, test_data = True)\n",
    "\n",
    "train_data_binary = create_data_batches(add_source(X_train_binary), y_train_binary)\n",
    "valid_data_binary = create_data_batches(add_source(X_valid_binary), y_valid_binary, valid_data = True)\n",
    "test_data_binary = create_data_batches(add_source(X_test_binary), y_test_binary, test_data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model(classify = 'binary'):\n",
    "    train_data = train_data_binary if classify == 'binary' else train_data_multi\n",
    "    valid_data = valid_data_binary if classify == 'binary' else valid_data_multi\n",
    "    outputShape = 2 if classify == 'binary' else 3\n",
    "    callBacks = [early_stopping_binary,learning_rate_reduce_binary] if classify == 'binary' else [early_stopping_multi,learning_rate_reduce_multi]\n",
    "    model = create_model([None,224,224,3],outputShape,classify,transfer=True)\n",
    "    #tensorboard = tf.keras.callbacks.TensorBoard(logdir)\n",
    "    model.fit(x=train_data,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            validation_data=valid_data,\n",
    "            validation_freq=1,\n",
    "            callbacks=callBacks\n",
    "             )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27/27 [==============================] - 13s 484ms/step - loss: 2.0864 - categorical_accuracy: 0.3118 - precision_5: 0.3099 - recall_5: 0.2753 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 6s 233ms/step - loss: 2.0121 - categorical_accuracy: 0.3200 - precision_5: 0.3160 - recall_5: 0.2788 - val_loss: 2.0390 - val_categorical_accuracy: 0.3416 - val_precision_5: 0.3408 - val_recall_5: 0.3128\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 6s 227ms/step - loss: 1.9395 - categorical_accuracy: 0.3271 - precision_5: 0.3320 - recall_5: 0.2965 - val_loss: 1.9701 - val_categorical_accuracy: 0.3416 - val_precision_5: 0.3484 - val_recall_5: 0.3169\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 6s 227ms/step - loss: 1.8816 - categorical_accuracy: 0.3376 - precision_5: 0.3433 - recall_5: 0.3094 - val_loss: 1.9111 - val_categorical_accuracy: 0.3333 - val_precision_5: 0.3532 - val_recall_5: 0.3169\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 6s 233ms/step - loss: 1.8293 - categorical_accuracy: 0.3541 - precision_5: 0.3552 - recall_5: 0.3188 - val_loss: 1.8635 - val_categorical_accuracy: 0.3457 - val_precision_5: 0.3594 - val_recall_5: 0.3210\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 6s 226ms/step - loss: 1.7931 - categorical_accuracy: 0.3635 - precision_5: 0.3633 - recall_5: 0.3282 - val_loss: 1.8199 - val_categorical_accuracy: 0.3457 - val_precision_5: 0.3581 - val_recall_5: 0.3169\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 6s 233ms/step - loss: 1.7742 - categorical_accuracy: 0.3718 - precision_5: 0.3735 - recall_5: 0.3353 - val_loss: 1.7863 - val_categorical_accuracy: 0.3580 - val_precision_5: 0.3620 - val_recall_5: 0.3292\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 6s 234ms/step - loss: 1.7380 - categorical_accuracy: 0.3753 - precision_5: 0.3821 - recall_5: 0.3412 - val_loss: 1.7571 - val_categorical_accuracy: 0.3704 - val_precision_5: 0.3779 - val_recall_5: 0.3374\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 6s 232ms/step - loss: 1.7013 - categorical_accuracy: 0.3847 - precision_5: 0.3908 - recall_5: 0.3494 - val_loss: 1.7306 - val_categorical_accuracy: 0.3827 - val_precision_5: 0.3843 - val_recall_5: 0.3416\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 6s 226ms/step - loss: 1.6892 - categorical_accuracy: 0.3929 - precision_5: 0.3929 - recall_5: 0.3518 - val_loss: 1.7108 - val_categorical_accuracy: 0.3827 - val_precision_5: 0.3917 - val_recall_5: 0.3498\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 6s 234ms/step - loss: 1.6674 - categorical_accuracy: 0.3965 - precision_5: 0.3955 - recall_5: 0.3541 - val_loss: 1.6903 - val_categorical_accuracy: 0.3868 - val_precision_5: 0.3944 - val_recall_5: 0.3457\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 6s 226ms/step - loss: 1.6650 - categorical_accuracy: 0.3918 - precision_5: 0.3997 - recall_5: 0.3565 - val_loss: 1.6727 - val_categorical_accuracy: 0.3868 - val_precision_5: 0.3991 - val_recall_5: 0.3498\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 6s 232ms/step - loss: 1.6431 - categorical_accuracy: 0.3976 - precision_5: 0.4021 - recall_5: 0.3576 - val_loss: 1.6563 - val_categorical_accuracy: 0.3992 - val_precision_5: 0.4028 - val_recall_5: 0.3498\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 6s 226ms/step - loss: 1.6127 - categorical_accuracy: 0.3988 - precision_5: 0.3976 - recall_5: 0.3565 - val_loss: 1.6422 - val_categorical_accuracy: 0.3951 - val_precision_5: 0.4123 - val_recall_5: 0.3580\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 6s 233ms/step - loss: 1.6048 - categorical_accuracy: 0.4012 - precision_5: 0.3976 - recall_5: 0.3565 - val_loss: 1.6264 - val_categorical_accuracy: 0.4074 - val_precision_5: 0.4218 - val_recall_5: 0.3663\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 6s 227ms/step - loss: 1.5678 - categorical_accuracy: 0.4000 - precision_5: 0.4034 - recall_5: 0.3612 - val_loss: 1.6157 - val_categorical_accuracy: 0.4074 - val_precision_5: 0.4186 - val_recall_5: 0.3704\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 6s 234ms/step - loss: 1.5972 - categorical_accuracy: 0.4047 - precision_5: 0.4063 - recall_5: 0.3624 - val_loss: 1.6035 - val_categorical_accuracy: 0.4115 - val_precision_5: 0.4286 - val_recall_5: 0.3827\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 6s 233ms/step - loss: 1.5759 - categorical_accuracy: 0.4118 - precision_5: 0.4092 - recall_5: 0.3659 - val_loss: 1.5916 - val_categorical_accuracy: 0.4280 - val_precision_5: 0.4286 - val_recall_5: 0.3827\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 6s 227ms/step - loss: 1.5527 - categorical_accuracy: 0.4176 - precision_5: 0.4118 - recall_5: 0.3682 - val_loss: 1.5811 - val_categorical_accuracy: 0.4280 - val_precision_5: 0.4259 - val_recall_5: 0.3786\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 6s 232ms/step - loss: 1.5565 - categorical_accuracy: 0.4188 - precision_5: 0.4170 - recall_5: 0.3753 - val_loss: 1.5704 - val_categorical_accuracy: 0.4321 - val_precision_5: 0.4259 - val_recall_5: 0.3786\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 6s 226ms/step - loss: 1.5409 - categorical_accuracy: 0.4176 - precision_5: 0.4201 - recall_5: 0.3741 - val_loss: 1.5603 - val_categorical_accuracy: 0.4239 - val_precision_5: 0.4259 - val_recall_5: 0.3786\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 6s 227ms/step - loss: 1.5167 - categorical_accuracy: 0.4176 - precision_5: 0.4225 - recall_5: 0.3753 - val_loss: 1.5512 - val_categorical_accuracy: 0.4156 - val_precision_5: 0.4299 - val_recall_5: 0.3786\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 6s 228ms/step - loss: 1.5113 - categorical_accuracy: 0.4212 - precision_5: 0.4278 - recall_5: 0.3765 - val_loss: 1.5409 - val_categorical_accuracy: 0.4239 - val_precision_5: 0.4332 - val_recall_5: 0.3868\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 6s 227ms/step - loss: 1.5124 - categorical_accuracy: 0.4224 - precision_5: 0.4291 - recall_5: 0.3776 - val_loss: 1.5407 - val_categorical_accuracy: 0.4239 - val_precision_5: 0.4332 - val_recall_5: 0.3868\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 6s 227ms/step - loss: 1.5144 - categorical_accuracy: 0.4224 - precision_5: 0.4291 - recall_5: 0.3776 - val_loss: 1.5405 - val_categorical_accuracy: 0.4239 - val_precision_5: 0.4332 - val_recall_5: 0.3868\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 6s 227ms/step - loss: 1.5143 - categorical_accuracy: 0.4224 - precision_5: 0.4284 - recall_5: 0.3765 - val_loss: 1.5403 - val_categorical_accuracy: 0.4239 - val_precision_5: 0.4332 - val_recall_5: 0.3868\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 6s 227ms/step - loss: 1.5085 - categorical_accuracy: 0.4224 - precision_5: 0.4284 - recall_5: 0.3765 - val_loss: 1.5403 - val_categorical_accuracy: 0.4239 - val_precision_5: 0.4332 - val_recall_5: 0.3868\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 6s 228ms/step - loss: 1.5111 - categorical_accuracy: 0.4224 - precision_5: 0.4284 - recall_5: 0.3765 - val_loss: 1.5403 - val_categorical_accuracy: 0.4239 - val_precision_5: 0.4332 - val_recall_5: 0.3868\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 6s 227ms/step - loss: 1.5181 - categorical_accuracy: 0.4224 - precision_5: 0.4284 - recall_5: 0.3765 - val_loss: 1.5403 - val_categorical_accuracy: 0.4239 - val_precision_5: 0.4332 - val_recall_5: 0.3868\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 6s 233ms/step - loss: 1.5065 - categorical_accuracy: 0.4224 - precision_5: 0.4284 - recall_5: 0.3765 - val_loss: 1.5403 - val_categorical_accuracy: 0.4239 - val_precision_5: 0.4332 - val_recall_5: 0.3868\n",
      "Epoch 1/100\n",
      "21/21 [==============================] - 12s 593ms/step - loss: 1.1748 - binary_accuracy: 0.4985 - precision_6: 0.4983 - recall_6: 0.4513 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 5s 236ms/step - loss: 1.1287 - binary_accuracy: 0.5000 - precision_6: 0.5000 - recall_6: 0.4408 - val_loss: 1.2161 - val_binary_accuracy: 0.4948 - val_precision_6: 0.4944 - val_recall_6: 0.4607\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 1.1138 - binary_accuracy: 0.5075 - precision_6: 0.5085 - recall_6: 0.4468 - val_loss: 1.1849 - val_binary_accuracy: 0.4974 - val_precision_6: 0.4972 - val_recall_6: 0.4607\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 5s 236ms/step - loss: 1.0835 - binary_accuracy: 0.5090 - precision_6: 0.5101 - recall_6: 0.4528 - val_loss: 1.1556 - val_binary_accuracy: 0.5052 - val_precision_6: 0.5056 - val_recall_6: 0.4764\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 5s 231ms/step - loss: 1.0531 - binary_accuracy: 0.5090 - precision_6: 0.5101 - recall_6: 0.4558 - val_loss: 1.1308 - val_binary_accuracy: 0.5026 - val_precision_6: 0.5028 - val_recall_6: 0.4660\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 5s 237ms/step - loss: 1.0320 - binary_accuracy: 0.5165 - precision_6: 0.5183 - recall_6: 0.4678 - val_loss: 1.1059 - val_binary_accuracy: 0.5183 - val_precision_6: 0.5200 - val_recall_6: 0.4764\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 5s 238ms/step - loss: 1.0048 - binary_accuracy: 0.5255 - precision_6: 0.5280 - recall_6: 0.4813 - val_loss: 1.0852 - val_binary_accuracy: 0.5236 - val_precision_6: 0.5260 - val_recall_6: 0.4764\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 0.9944 - binary_accuracy: 0.5277 - precision_6: 0.5305 - recall_6: 0.4828 - val_loss: 1.0647 - val_binary_accuracy: 0.5262 - val_precision_6: 0.5287 - val_recall_6: 0.4817\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 5s 237ms/step - loss: 0.9736 - binary_accuracy: 0.5300 - precision_6: 0.5327 - recall_6: 0.4888 - val_loss: 1.0470 - val_binary_accuracy: 0.5288 - val_precision_6: 0.5314 - val_recall_6: 0.4869\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 5s 229ms/step - loss: 0.9539 - binary_accuracy: 0.5337 - precision_6: 0.5366 - recall_6: 0.4948 - val_loss: 1.0314 - val_binary_accuracy: 0.5236 - val_precision_6: 0.5254 - val_recall_6: 0.4869\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 5s 233ms/step - loss: 0.9308 - binary_accuracy: 0.5315 - precision_6: 0.5341 - recall_6: 0.4933 - val_loss: 1.0157 - val_binary_accuracy: 0.5236 - val_precision_6: 0.5257 - val_recall_6: 0.4817\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 5s 237ms/step - loss: 0.9267 - binary_accuracy: 0.5390 - precision_6: 0.5422 - recall_6: 0.5007 - val_loss: 1.0017 - val_binary_accuracy: 0.5314 - val_precision_6: 0.5349 - val_recall_6: 0.4817\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 5s 233ms/step - loss: 0.9133 - binary_accuracy: 0.5472 - precision_6: 0.5512 - recall_6: 0.5082 - val_loss: 0.9893 - val_binary_accuracy: 0.5314 - val_precision_6: 0.5345 - val_recall_6: 0.4869\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 5s 236ms/step - loss: 0.8997 - binary_accuracy: 0.5495 - precision_6: 0.5537 - recall_6: 0.5097 - val_loss: 0.9782 - val_binary_accuracy: 0.5340 - val_precision_6: 0.5367 - val_recall_6: 0.4974\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 0.8900 - binary_accuracy: 0.5510 - precision_6: 0.5550 - recall_6: 0.5142 - val_loss: 0.9676 - val_binary_accuracy: 0.5366 - val_precision_6: 0.5389 - val_recall_6: 0.5079\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 5s 238ms/step - loss: 0.8807 - binary_accuracy: 0.5562 - precision_6: 0.5600 - recall_6: 0.5247 - val_loss: 0.9575 - val_binary_accuracy: 0.5471 - val_precision_6: 0.5495 - val_recall_6: 0.5236\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 5s 238ms/step - loss: 0.8665 - binary_accuracy: 0.5562 - precision_6: 0.5598 - recall_6: 0.5262 - val_loss: 0.9480 - val_binary_accuracy: 0.5576 - val_precision_6: 0.5604 - val_recall_6: 0.5340\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 5s 237ms/step - loss: 0.8669 - binary_accuracy: 0.5592 - precision_6: 0.5624 - recall_6: 0.5337 - val_loss: 0.9385 - val_binary_accuracy: 0.5602 - val_precision_6: 0.5628 - val_recall_6: 0.5393\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 0.8531 - binary_accuracy: 0.5637 - precision_6: 0.5667 - recall_6: 0.5412 - val_loss: 0.9310 - val_binary_accuracy: 0.5628 - val_precision_6: 0.5645 - val_recall_6: 0.5497\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 5s 230ms/step - loss: 0.8545 - binary_accuracy: 0.5735 - precision_6: 0.5763 - recall_6: 0.5547 - val_loss: 0.9228 - val_binary_accuracy: 0.5602 - val_precision_6: 0.5622 - val_recall_6: 0.5445\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 5s 233ms/step - loss: 0.8524 - binary_accuracy: 0.5720 - precision_6: 0.5745 - recall_6: 0.5547 - val_loss: 0.9157 - val_binary_accuracy: 0.5628 - val_precision_6: 0.5645 - val_recall_6: 0.5497\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 5s 228ms/step - loss: 0.8317 - binary_accuracy: 0.5720 - precision_6: 0.5741 - recall_6: 0.5577 - val_loss: 0.9085 - val_binary_accuracy: 0.5628 - val_precision_6: 0.5645 - val_recall_6: 0.5497\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 5s 231ms/step - loss: 0.8282 - binary_accuracy: 0.5735 - precision_6: 0.5754 - recall_6: 0.5607 - val_loss: 0.9084 - val_binary_accuracy: 0.5628 - val_precision_6: 0.5645 - val_recall_6: 0.5497\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 5s 230ms/step - loss: 0.8255 - binary_accuracy: 0.5735 - precision_6: 0.5754 - recall_6: 0.5607 - val_loss: 0.9082 - val_binary_accuracy: 0.5628 - val_precision_6: 0.5645 - val_recall_6: 0.5497\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 5s 231ms/step - loss: 0.8303 - binary_accuracy: 0.5735 - precision_6: 0.5754 - recall_6: 0.5607 - val_loss: 0.9081 - val_binary_accuracy: 0.5628 - val_precision_6: 0.5645 - val_recall_6: 0.5497\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 5s 229ms/step - loss: 0.8332 - binary_accuracy: 0.5735 - precision_6: 0.5754 - recall_6: 0.5607 - val_loss: 0.9081 - val_binary_accuracy: 0.5628 - val_precision_6: 0.5645 - val_recall_6: 0.5497\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 5s 232ms/step - loss: 0.8273 - binary_accuracy: 0.5735 - precision_6: 0.5754 - recall_6: 0.5607 - val_loss: 0.9081 - val_binary_accuracy: 0.5628 - val_precision_6: 0.5645 - val_recall_6: 0.5497\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 5s 230ms/step - loss: 0.8322 - binary_accuracy: 0.5735 - precision_6: 0.5754 - recall_6: 0.5607 - val_loss: 0.9081 - val_binary_accuracy: 0.5628 - val_precision_6: 0.5645 - val_recall_6: 0.5497\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 5s 242ms/step - loss: 0.8238 - binary_accuracy: 0.5735 - precision_6: 0.5754 - recall_6: 0.5607 - val_loss: 0.9080 - val_binary_accuracy: 0.5628 - val_precision_6: 0.5645 - val_recall_6: 0.5497\n"
     ]
    }
   ],
   "source": [
    "model_multi = train_model('multi')\n",
    "model_binary = train_model('binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 371ms/step\n",
      "3/3 [==============================] - 1s 420ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_multi = model_multi.predict(test_data_multi, verbose = 1)\n",
    "predict_binary = model_binary.predict(test_data_binary, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_label(prediction_probabilities, classify = 'binary'):\n",
    "    unique_textures = np.asarray([1,2]) if classify == 'binary' else np.asarray([1,2,3])\n",
    "    predict_labels = []\n",
    "    for prediction_probability in prediction_probabilities:\n",
    "        predict_labels.append(unique_textures[np.argmax(prediction_probability)])\n",
    "    return np.asarray(predict_labels)\n",
    "def unbatchify(data, classify = 'binary'):\n",
    "    unique_textures = np.asarray([1,2]) if classify == 'binary' else np.asarray([1,2,3])\n",
    "    labels = []\n",
    "    for image, label in data.unbatch():\n",
    "        labels.append(unique_textures[np.argmax(label)])\n",
    "    return np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'Non-solid'), Text(0, 1.5, 'Part-solid'), Text(0, 2.5, 'Solid')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_labels_multi = unbatchify(test_data_multi,'multi')\n",
    "test_labels_binary = unbatchify(test_data_binary)\n",
    "predict_labels_multi = get_pred_label(predict_multi,'multi')\n",
    "predict_labels_binary = get_pred_label(predict_binary)\n",
    "# df = pd.DataFrame(classification_report(test_labels_multi,predict_labels_multi,target_names=['Non-solid','Part-solid','Solid'],output_dict = True,zero_division=1))\n",
    "# df = df.drop(columns=['macro avg','weighted avg'])\n",
    "# df['accuracy'][0:3]=np.NaN\n",
    "# df = df.rename({'support':\"samples\"})\n",
    "# classificationReport = sns.heatmap(df.T, annot=True, vmin = 0, vmax = 1, fmt=\".3f\", cmap='GnBu',square = True, robust= True)\n",
    "# classificationReport.set_yticklabels(classificationReport.get_yticklabels(), rotation=0, ha=\"right\")\n",
    "\n",
    "cfm_acc = sns.heatmap(confusion_matrix(test_labels_multi,predict_labels_multi), annot=True, fmt='d', cmap='GnBu')\n",
    "cfm_acc.set_xlabel('Predicted labels')\n",
    "cfm_acc.set_ylabel('True labels')\n",
    "cfm_acc.xaxis.set_ticklabels(['Non-solid','Part-solid','Solid'])\n",
    "cfm_acc.yaxis.set_ticklabels(['Non-solid','Part-solid','Solid'])\n",
    "cfm_acc.set_yticklabels(cfm_acc.get_yticklabels(), rotation=0, ha=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_multi = pd.DataFrame(np.asarray([test_labels_multi,predict_labels_multi]).T,columns=[\"y_test\",\"y_pred\"])\n",
    "record_multi.to_csv(\"/storage/huybq/LIDC/csvData/balanced/heatmap/heatmap_64/record3_multi.csv\")\n",
    "# np.asarray([test_labels_multi,predict_labels_multi]).T\n",
    "record_binary = pd.DataFrame(np.asarray([test_labels_binary,predict_labels_binary]).T,columns=[\"y_test\",\"y_pred\"])\n",
    "record_binary.to_csv(\"/storage/huybq/LIDC/csvData/balanced/heatmap/heatmap_64/record3_binary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_multi = pd.DataFrame(np.asarray([test_labels_multi,predict_labels_multi]).T,columns=[\"y_test\",\"y_pred\"])\n",
    "record_multi.to_csv(\"/storage/huybq/LIDC/csvData/balanced/grey/grey_64/record3_multi.csv\")\n",
    "# np.asarray([test_labels_multi,predict_labels_multi]).T\n",
    "record_binary = pd.DataFrame(np.asarray([test_labels_binary,predict_labels_binary]).T,columns=[\"y_test\",\"y_pred\"])\n",
    "record_binary.to_csv(\"/storage/huybq/LIDC/csvData/balanced/grey/grey_64/record3_binary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultGenerator(test_labels, predict_labels, scenario, dataType, case, index,classify = 'binary'):\n",
    "    print(precision_recall_fscore_support(test_labels,predict_labels,zero_division=1,average = 'weighted'),classify)\n",
    "    labels = ['Non-solid','Solid'] if classify == 'binary' else ['Non-solid','Part-solid','Solid']\n",
    "    df = pd.DataFrame(classification_report(test_labels,predict_labels,target_names=labels,output_dict = True,zero_division=1))\n",
    "    df = df.drop(columns=['macro avg','weighted avg'])\n",
    "    df['accuracy'][0:3]=np.NaN\n",
    "    df = df.rename({'support':\"samples\"})\n",
    "    classificationReport = sns.heatmap(df.T, annot=True, vmin = 0, vmax = 1, fmt=\".3f\", cmap='GnBu',square = True, robust= True)\n",
    "    classificationReport.set_yticklabels(classificationReport.get_yticklabels(), rotation=0, ha=\"right\")\n",
    "#     plt.savefig(f\"/storage/huybq/LIDC/figure/{scenario}/{dataType}/{dataType}{case}/result{index}_classificationReport_{classify}.png\",dpi=360,bbox_inches='tight')\n",
    "#     plt.clf()\n",
    "#     cfm_acc = sns.heatmap(confusion_matrix(test_labels,predict_labels,nomalize=[]), annot=True, fmt='d', cmap='GnBu')\n",
    "#     cfm_acc.set_xlabel('Predicted labels')\n",
    "#     cfm_acc.set_ylabel('True labels')\n",
    "#     cfm_acc.xaxis.set_ticklabels(labels)\n",
    "#     cfm_acc.yaxis.set_ticklabels(labels)\n",
    "#     cfm_acc.set_yticklabels(cfm_acc.get_yticklabels(), rotation=0, ha=\"right\")\n",
    "#     plt.savefig(f\"/storage/huybq/LIDC/figure/{scenario}/{dataType}/{dataType}{case}/result{index}_confusionMatrix_{classify}.png\",dpi=360,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented heatmap 64 1\n",
      "(0.7965103513410272, 0.7830188679245284, 0.7833327546439128, None) multi\n",
      "(0.9000190694126621, 0.8768115942028986, 0.8832109919066441, None) binary\n",
      "augmented heatmap 64 2\n",
      "(0.8144199439266501, 0.7924528301886793, 0.7966758668536869, None) multi\n",
      "(0.9099119282680884, 0.894927536231884, 0.8992783830409946, None) binary\n",
      "augmented heatmap 64 3\n",
      "(0.8015310125357374, 0.7830188679245284, 0.7865157580301873, None) multi\n",
      "(0.9066742944317315, 0.8840579710144928, 0.8900809335591944, None) binary\n",
      "augmented heatmap 32 1\n",
      "(0.7824210113900315, 0.7328519855595668, 0.743827880001458, None) multi\n",
      "(0.8842709890628689, 0.84, 0.8525143678160919, None) binary\n",
      "augmented heatmap 32 2\n",
      "(0.7730280508856295, 0.7725631768953068, 0.7602863109912658, None) multi\n",
      "(0.8827295248104496, 0.824, 0.8396322317633792, None) binary\n",
      "augmented heatmap 32 3\n",
      "(0.7792657003060346, 0.779783393501805, 0.774319232759279, None) multi\n",
      "(0.8802786452077828, 0.84, 0.8518680119989092, None) binary\n",
      "augmented grey 64 1\n",
      "(0.7900767247448874, 0.779874213836478, 0.782154728878558, None) multi\n",
      "(0.9119505447590424, 0.9021739130434783, 0.9052940696631048, None) binary\n",
      "augmented grey 64 2\n",
      "(0.8228094756280949, 0.8113207547169812, 0.8137399465329308, None) multi\n",
      "(0.9234039799063024, 0.9094202898550725, 0.9131710198629263, None) binary\n",
      "augmented grey 64 3\n",
      "(0.815843759380249, 0.7987421383647799, 0.8030268423588219, None) multi\n",
      "(0.891228649682756, 0.8586956521739131, 0.8673322295847942, None) binary\n",
      "augmented grey 32 1\n",
      "(0.7727121517171156, 0.776173285198556, 0.7702182625111782, None) multi\n",
      "(0.9050583149824647, 0.872, 0.8809425625920472, None) binary\n",
      "augmented grey 32 2\n",
      "(0.7889532248738025, 0.779783393501805, 0.7804021207460878, None) multi\n",
      "(0.9014054054054054, 0.872, 0.8803543123543124, None) binary\n",
      "augmented grey 32 3\n",
      "(0.7840864911262023, 0.7509025270758123, 0.7479999140740927, None) multi\n",
      "(0.8962023270846801, 0.86, 0.8700875808922733, None) binary\n",
      "balanced heatmap 64 1\n",
      "(0.7416187327698955, 0.7320261437908496, 0.7265660573305319, None) multi\n",
      "(0.8234317266575331, 0.8198198198198198, 0.8192031666607937, None) binary\n",
      "balanced heatmap 64 2\n",
      "(0.7145877790114495, 0.7058823529411765, 0.6975776913576467, None) multi\n",
      "(0.831655184596361, 0.8288288288288288, 0.8285506148163605, None) binary\n",
      "balanced heatmap 64 3\n",
      "(0.7408115637035687, 0.738562091503268, 0.730001355380862, None) multi\n",
      "(0.8289078552236447, 0.8288288288288288, 0.8288010345329498, None) binary\n",
      "balanced heatmap 32 1\n",
      "(0.17192147531231408, 0.4146341463414634, 0.24306139613120267, None) multi\n",
      "(0.2822265625, 0.53125, 0.3686224489795918, None) binary\n",
      "balanced heatmap 32 2\n",
      "(0.17192147531231408, 0.4146341463414634, 0.24306139613120267, None) multi\n",
      "(0.2822265625, 0.53125, 0.3686224489795918, None) binary\n",
      "balanced heatmap 32 3\n",
      "(0.17192147531231408, 0.4146341463414634, 0.24306139613120267, None) multi\n",
      "(0.2822265625, 0.53125, 0.3686224489795918, None) binary\n",
      "balanced grey 64 1\n",
      "(0.7000653009112844, 0.6993464052287581, 0.6899700363044345, None) multi\n",
      "(0.803250309132662, 0.8018018018018018, 0.8014794234703149, None) binary\n",
      "balanced grey 64 2\n",
      "(0.7285849197613904, 0.7320261437908496, 0.7281387510641308, None) multi\n",
      "(0.8298750930501093, 0.8288288288288288, 0.8287454459411916, None) binary\n",
      "balanced grey 64 3\n",
      "(0.7408115637035687, 0.738562091503268, 0.730001355380862, None) multi\n",
      "(0.8289078552236447, 0.8288288288288288, 0.8288010345329498, None) binary\n",
      "balanced grey 32 1\n",
      "(0.17192147531231408, 0.4146341463414634, 0.24306139613120267, None) multi\n",
      "(0.2822265625, 0.53125, 0.3686224489795918, None) binary\n",
      "balanced grey 32 2\n",
      "(0.17192147531231408, 0.4146341463414634, 0.24306139613120267, None) multi\n",
      "(0.2822265625, 0.53125, 0.3686224489795918, None) binary\n",
      "balanced grey 32 3\n",
      "(0.17192147531231408, 0.4146341463414634, 0.24306139613120267, None) multi\n",
      "(0.2822265625, 0.53125, 0.3686224489795918, None) binary\n"
     ]
    }
   ],
   "source": [
    "plt.cla()\n",
    "plt.clf()\n",
    "plt.close()\n",
    "#define scenario\n",
    "scenarios = ['augmented','balanced']\n",
    "#define data type\n",
    "dataTypes = ['heatmap','grey']\n",
    "#define case\n",
    "cases = [64,32]\n",
    "#define index\n",
    "test_labels_multi = np.asarray([])\n",
    "predict_labels_multi = np.asarray([])\n",
    "test_labels_binary = np.asarray([])\n",
    "predict_labels_binary = np.asarray([])\n",
    "for scenario in scenarios:\n",
    "    for dataType in dataTypes:\n",
    "        for case in cases:\n",
    "            for index in range(1,4): \n",
    "                print(scenario, dataType, case, index)\n",
    "                record_multi = pd.read_csv(f\"/storage/huybq/LIDC/csvData/{scenario}/{dataType}/{dataType}_{case}/record{index}_multi.csv\")\n",
    "                record_binary = pd.read_csv(f\"/storage/huybq/LIDC/csvData/{scenario}/{dataType}/{dataType}_{case}/record{index}_binary.csv\")\n",
    "#                 test_labels_multi= np.append(test_labels_multi,record_multi['y_test'].to_numpy())\n",
    "#                 predict_labels_multi= np.append(predict_labels_multi,record_multi['y_pred'].to_numpy())\n",
    "#                 test_labels_binary= np.append(test_labels_binary,record_binary['y_test'].to_numpy())\n",
    "#                 predict_labels_binary= np.append(predict_labels_binary,record_binary['y_pred'].to_numpy())\n",
    "                test_labels_multi = record_multi['y_test']\n",
    "                predict_labels_multi = record_multi['y_pred']\n",
    "                test_labels_binary = record_binary['y_test']\n",
    "                predict_labels_binary = record_binary['y_pred']\n",
    "                resultGenerator(test_labels_multi, predict_labels_multi, scenario, dataType, case, index ,'multi')\n",
    "                resultGenerator(test_labels_binary, predict_labels_binary, scenario, dataType, case, index ,'binary')\n",
    "# record_multi = pd.read_csv(f\"/storage/huybq/LIDC/csvData/{scenario}/{dataType}/{dataType}_{case}/record{index}_multi.csv\")\n",
    "# record_binary = pd.read_csv(f\"/storage/huybq/LIDC/csvData/{scenario}/{dataType}/{dataType}_{case}/record{index}_binary.csv\")\n",
    "\n",
    "# test_labels_multi = record_multi['y_test']\n",
    "# predict_labels_multi = record_multi['y_pred']\n",
    "# test_labels_binary = record_binary['y_test']\n",
    "# predict_labels_binary = record_binary['y_pred']\n",
    "# resultGenerator(test_labels_multi, predict_labels_multi, scenario, dataType, case, 3,'multi')\n",
    "# resultGenerator(test_labels_binary, predict_labels_binary, scenario, dataType, case, 3,'binary')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
